# CAPT Feedback Integration Guide for PhonoEcho

## Overview
This guide shows how to integrate the CAPT (Computer-Assisted Pronunciation Training) feedback pipeline into your `phonoecho.py` Streamlit app, specifically displaying results in the "AIãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯" container.

## Integration Strategy

The CAPT pipeline reduces token usage from ~8000 to ~800 (90% reduction) by:
1. **First attempt**: Parse full Azure JSON â†’ create stable **Guidance Card** (saved once)
2. **Subsequent attempts**: Parse incrementally â†’ create **Attempt Summary** (lighter payload)
3. **Generate feedback**: Use GPT with the compact data structures

---

## ğŸ¯ Implementation Ideas

### Idea 1: **Progressive Feedback Display** (Recommended)
Show different feedback types based on practice attempt number:
- **First attempt**: Comprehensive guidance with all error types and patterns
- **Subsequent attempts**: Focused feedback on specific improvements

### Idea 2: **Tabbed Feedback Interface**
Display multiple feedback views in tabs within the AIãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ container:
- ğŸ“Š Overview
- ğŸ¯ Focus Areas
- ğŸ’¡ Practice Tips
- ğŸ“ˆ Progress

### Idea 3: **Interactive Feedback Cards**
Show expandable cards for each error category with examples and tips.

### Idea 4: **Comparative Feedback**
Compare current attempt with previous attempt to show improvement.

---

## ğŸ“ Step-by-Step Integration

### Step 1: Import CAPT Modules
Add to the top of `phonoecho.py`:

```python
from capt_integration import CAPTFeedbackPipeline
from capt_config import FeedbackConfig
```

### Step 2: Initialize CAPT Pipeline
Add to `initialize_session_state()` in `initialize.py`:

```python
if "capt_pipeline" not in session_state:
    config = FeedbackConfig(
        fair_threshold=60.0,  # Minimum score for "fair" rating
        phoneme_error_threshold=70.0,  # Phoneme scores below this are errors
        word_error_threshold=70.0,  # Word scores below this are problematic
        prosody_error_threshold=65.0,  # Prosody scores below this indicate issues
        max_attempt_errors=5  # Maximum errors to report per attempt
    )
    session_state.capt_pipeline = CAPTFeedbackPipeline(config)

if "guidance_card" not in session_state:
    session_state.guidance_card = None  # First attempt creates this

if "ai_feedback_text" not in session_state:
    session_state.ai_feedback_text = None  # Store generated feedback
```

### Step 3: Process Pronunciation Results
Replace the section after getting `pronunciation_assessment_result` in `phonoecho.py`:

```python
if submitted:
    # Get pronunciation assessment
    st.session_state.practice_times += 1
    audio_file_path = f"asset/{user}/history/{lesson}-{st.session_state.practice_times}.wav"
    save_audio_to_file(audio_bytes_io, filename=audio_file_path)
    pronunciation_assessment_result = get_pronunciation_assessment(
        user, 
        st.session_state.pronunciation_config, 
        reference_text, 
        audio_file_path
    )
    save_pronunciation_assessment(
        pronunciation_assessment_result, 
        f"asset/{user}/history/{lesson}-{st.session_state.practice_times}.json"
    )

    # CAPT Processing
    if st.session_state.practice_times == 1:
        # First attempt: Create guidance card
        guidance_card = st.session_state.capt_pipeline.parse_guidance_card(
            pronunciation_assessment_result
        )
        st.session_state.guidance_card = guidance_card
        
        # Save guidance card for reuse
        guidance_path = f"asset/{user}/history/{lesson}_guidance.json"
        st.session_state.capt_pipeline.save_guidance_card(guidance_card, guidance_path)
        
        # Generate comprehensive feedback
        feedback_prompt = st.session_state.capt_pipeline.generate_feedback(
            guidance_card=guidance_card,
            attempt_summary=None,
            reference_text=reference_text,
            is_first_attempt=True
        )
    else:
        # Subsequent attempts: Create attempt summary
        attempt_summary = st.session_state.capt_pipeline.parse_attempt_summary(
            pronunciation_assessment_result
        )
        
        # Save attempt summary
        attempt_path = f"asset/{user}/history/{lesson}-{st.session_state.practice_times}_summary.json"
        st.session_state.capt_pipeline.save_attempt_summary(attempt_summary, attempt_path)
        
        # Generate focused feedback
        feedback_prompt = st.session_state.capt_pipeline.generate_feedback(
            guidance_card=st.session_state.guidance_card,
            attempt_summary=attempt_summary,
            reference_text=reference_text,
            is_first_attempt=False
        )
    
    # Generate AI feedback using OpenAI
    st.session_state.ai_feedback_text = generate_ai_feedback_from_prompt(
        st.session_state.openai_client,
        feedback_prompt
    )
    
    # Create visualization (radar chart)
    radar_chart = create_radar_chart(pronunciation_assessment_result)
    st.session_state["feedback"]["radar_chart"] = radar_chart
```

### Step 4: Create AI Feedback Generator Function
Add this function to `ai_feedback.py`:

```python
def generate_ai_feedback_from_prompt(client, feedback_prompt):
    """
    Generate AI feedback using the structured CAPT feedback prompt.
    
    Args:
        client: OpenAI client instance
        feedback_prompt: FeedbackPrompt dataclass from CAPT pipeline
    
    Returns:
        str: Generated feedback text
    """
    # Build system prompt
    system_prompt = """ã‚ãªãŸã¯ç™ºéŸ³æŒ‡å°ã®å°‚é–€å®¶ã§ã™ã€‚
å­¦ç¿’è€…ã®ç™ºéŸ³è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ã€å…·ä½“çš„ã§å®Ÿè¡Œå¯èƒ½ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æ—¥æœ¬èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚

ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«ã¯ä»¥ä¸‹ã‚’å«ã‚ã¦ãã ã•ã„ï¼š
1. å…¨ä½“çš„ãªè©•ä¾¡ï¼ˆè‚¯å®šçš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‹ã‚‰å§‹ã‚ã‚‹ï¼‰
2. æ”¹å–„ãŒå¿…è¦ãªä¸»è¦ãªãƒã‚¤ãƒ³ãƒˆï¼ˆå„ªå…ˆé †ä½é †ï¼‰
3. å…·ä½“çš„ãªç·´ç¿’æ–¹æ³•
4. åŠ±ã¾ã—ã®è¨€è‘‰

ç°¡æ½”ã§åˆ†ã‹ã‚Šã‚„ã™ã„è¨€è‘‰ã‚’ä½¿ã„ã€å­¦ç¿’è€…ãŒæ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’ç†è§£ã§ãã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚"""
    
    # Build user prompt from FeedbackPrompt
    user_prompt = f"""
ã€ç™ºéŸ³è©•ä¾¡ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã€‘

å‚ç…§ãƒ†ã‚­ã‚¹ãƒˆ: {feedback_prompt.reference_text}

ã‚¹ã‚³ã‚¢:
- ç™ºéŸ³ã‚¹ã‚³ã‚¢: {feedback_prompt.overall_scores.pronunciation_score}/100
- æ­£ç¢ºã•: {feedback_prompt.overall_scores.accuracy_score}/100
- æµæš¢ã•: {feedback_prompt.overall_scores.fluency_score}/100
- å®Œå…¨æ€§: {feedback_prompt.overall_scores.completeness_score}/100

"""
    
    # Add prosody issues
    if feedback_prompt.prosody_issues:
        user_prompt += "éŸ»å¾‹ã®å•é¡Œ:\n"
        for issue in feedback_prompt.prosody_issues:
            user_prompt += f"- {issue.error_type.value}: å˜èªã€Œ{issue.word}ã€(æ·±åˆ»åº¦: {issue.severity})\n"
        user_prompt += "\n"
    
    # Add word errors
    if feedback_prompt.word_errors:
        user_prompt += "å˜èªãƒ¬ãƒ™ãƒ«ã®ã‚¨ãƒ©ãƒ¼:\n"
        for error in feedback_prompt.word_errors:
            user_prompt += f"- {error.error_type.value}: å˜èªã€Œ{error.word}ã€"
            if error.phoneme_errors:
                phonemes = ", ".join([f"{p.phoneme}({p.accuracy_score}ç‚¹)" 
                                     for p in error.phoneme_errors])
                user_prompt += f" [éŸ³ç´ : {phonemes}]"
            user_prompt += "\n"
        user_prompt += "\n"
    
    # Add practice recommendations
    if feedback_prompt.practice_recommendations:
        user_prompt += "æ¨å¥¨ã•ã‚Œã‚‹ç·´ç¿’:\n"
        for i, rec in enumerate(feedback_prompt.practice_recommendations, 1):
            user_prompt += f"{i}. {rec}\n"
    
    try:
        response = client.chat.completions.create(
            model="gpt-4",  # or "gpt-5-mini" if available
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            temperature=0.7,
            max_tokens=800
        )
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"Error generating AI feedback: {e}")
        return "ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"
```

### Step 5: Display Feedback in AIãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ Container

Replace the AIãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ container section in `phonoecho.py`:

```python
with st.container(height=450, horizontal_alignment="center", vertical_alignment="center"):
    if st.session_state.ai_feedback_text is None:
        st.html("<h2 style='text-align: center;'>AIãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯</h2>")
        st.info("éŸ³å£°ã‚’éŒ²éŸ³ã—ã¦ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å–å¾—ã—ã¦ãã ã•ã„")
    else:
        st.markdown("### ğŸ¯ AIãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯")
        
        # Display practice attempt number
        st.caption(f"ç·´ç¿’å›æ•°: {st.session_state.practice_times}")
        
        # Display feedback with nice formatting
        st.markdown(st.session_state.ai_feedback_text)
        
        # Add a divider
        st.divider()
        
        # Show token savings info (optional)
        with st.expander("ğŸ“Š æŠ€è¡“æƒ…å ±", expanded=False):
            if st.session_state.practice_times == 1:
                st.write("âœ… åˆå›: ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚«ãƒ¼ãƒ‰ã‚’ä½œæˆã—ã¾ã—ãŸ")
                st.write("ğŸ“ ãƒ•ãƒ«JSONè§£æï¼ˆç´„8000ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰")
            else:
                st.write("âœ… 2å›ç›®ä»¥é™: å·®åˆ†ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨")
                st.write("ğŸ“ è»½é‡ã‚µãƒãƒªãƒ¼ï¼ˆç´„800ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰")
                st.write("ğŸ’¡ ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’90%å‰Šæ¸›")
```

---

## ğŸ¨ Enhanced Display Ideas

### Option A: Tabbed Feedback Display
```python
with st.container(height=450):
    if st.session_state.ai_feedback_text is not None:
        feedback_tabs = st.tabs(["ğŸ“Š ç·è©•", "ğŸ¯ æ”¹å–„ç‚¹", "ğŸ’¡ ç·´ç¿’æ–¹æ³•"])
        
        with feedback_tabs[0]:
            # Overall feedback and scores
            st.markdown(st.session_state.ai_feedback_text)
        
        with feedback_tabs[1]:
            # Show specific errors from guidance card or attempt summary
            if st.session_state.guidance_card:
                st.write("ä¸»ãªæ”¹å–„ç‚¹:")
                for error in st.session_state.guidance_card.word_errors[:3]:
                    st.error(f"**{error.word}**: {error.error_type.value}")
        
        with feedback_tabs[2]:
            # Practice recommendations
            st.write("æ¨å¥¨ã•ã‚Œã‚‹ç·´ç¿’:")
            recs = [
                "é…ã„ã‚¹ãƒ”ãƒ¼ãƒ‰ã§ç¹°ã‚Šè¿”ã—ç·´ç¿’ã—ã¦ãã ã•ã„",
                "å•é¡Œã®ã‚ã‚‹éŸ³ç´ ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ãã ã•ã„",
                "ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã®éŸ³å£°ã‚’èã„ã¦æ¨¡å€£ã—ã¦ãã ã•ã„"
            ]
            for rec in recs:
                st.write(f"â€¢ {rec}")
```

### Option B: Progress Comparison
```python
with st.container(height=450):
    if st.session_state.practice_times > 1 and st.session_state.ai_feedback_text:
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric(
                label="ç™ºéŸ³ã‚¹ã‚³ã‚¢",
                value=f"{st.session_state.guidance_card.overall_scores.pronunciation_score}",
                delta="+5"  # Calculate from previous attempt
            )
        
        with col2:
            st.metric(
                label="ã‚¨ãƒ©ãƒ¼æ•°",
                value=len(st.session_state.guidance_card.word_errors),
                delta="-2"  # Calculate from previous attempt
            )
        
        st.divider()
        st.markdown(st.session_state.ai_feedback_text)
```

### Option C: Interactive Error Cards
```python
with st.container(height=450):
    if st.session_state.guidance_card and st.session_state.ai_feedback_text:
        st.markdown("### ğŸ¯ AIãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯")
        st.markdown(st.session_state.ai_feedback_text)
        
        st.divider()
        
        # Show expandable error details
        if st.session_state.guidance_card.word_errors:
            st.write("**è©³ç´°ãªã‚¨ãƒ©ãƒ¼åˆ†æ:**")
            for error in st.session_state.guidance_card.word_errors[:3]:
                with st.expander(f"âŒ {error.word} - {error.error_type.value}"):
                    st.write(f"**ã‚¹ã‚³ã‚¢**: {error.accuracy_score}/100")
                    if error.phoneme_errors:
                        st.write("**å•é¡Œã®ã‚ã‚‹éŸ³ç´ :**")
                        for phoneme in error.phoneme_errors:
                            st.write(f"- /{phoneme.phoneme}/ â†’ ã‚¹ã‚³ã‚¢: {phoneme.accuracy_score}")
```

---

## ğŸ“Š Complete Example Integration

Here's a complete modified section for `phonoecho.py`:

```python
with cols[1]:
    # Radar Chart Container
    with st.container(height=400, horizontal_alignment="center", vertical_alignment="center"):
        if st.session_state["feedback"]["radar_chart"] is None:
            st.html("<h1 style='text-align: center;'>ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ</h1>")
        else:
            st.pyplot(st.session_state["feedback"]["radar_chart"], width=450)

    # AI Feedback Container (ENHANCED)
    with st.container(height=450, horizontal_alignment="center", vertical_alignment="center"):
        if st.session_state.ai_feedback_text is None:
            st.html("<h2 style='text-align: center;'>AIãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯</h2>")
            st.info("ğŸ¤ éŸ³å£°ã‚’éŒ²éŸ³ã—ã¦ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å—ã‘å–ã‚Šã¾ã—ã‚‡ã†ï¼")
        else:
            # Header with practice count
            st.markdown(f"### ğŸ¯ AIãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ (ç·´ç¿’ #{st.session_state.practice_times})")
            
            # Main feedback text
            st.markdown(st.session_state.ai_feedback_text)
            
            # Visual separator
            st.divider()
            
            # Additional insights
            col1, col2, col3 = st.columns(3)
            
            with col1:
                if st.session_state.guidance_card:
                    score = st.session_state.guidance_card.overall_scores.pronunciation_score
                    st.metric("ç™ºéŸ³ã‚¹ã‚³ã‚¢", f"{score}/100")
            
            with col2:
                if st.session_state.guidance_card:
                    errors = len(st.session_state.guidance_card.word_errors)
                    st.metric("ã‚¨ãƒ©ãƒ¼æ•°", errors)
            
            with col3:
                st.metric("ç·´ç¿’å›æ•°", st.session_state.practice_times)
```

---

## ğŸ”§ Additional Features

### Feature 1: Feedback History
Store and display feedback history:

```python
# In initialize.py
if "feedback_history" not in session_state:
    session_state.feedback_history = []

# After generating feedback
st.session_state.feedback_history.append({
    "attempt": st.session_state.practice_times,
    "feedback": st.session_state.ai_feedback_text,
    "score": guidance_card.overall_scores.pronunciation_score,
    "timestamp": datetime.now()
})
```

### Feature 2: Download Feedback Report
```python
if st.session_state.ai_feedback_text:
    st.download_button(
        label="ğŸ“¥ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=st.session_state.ai_feedback_text,
        file_name=f"feedback_{user}_{lesson}_{st.session_state.practice_times}.txt",
        mime="text/plain"
    )
```

---

## ğŸ¯ Token Savings Demonstration

Show users the efficiency gains:

```python
with st.expander("ğŸ’¡ ãƒˆãƒ¼ã‚¯ãƒ³åŠ¹ç‡ã«ã¤ã„ã¦"):
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**å¾“æ¥ã®æ–¹æ³•**")
        st.write("âŒ æ¯å›ãƒ•ãƒ«JSONé€ä¿¡")
        st.write("ğŸ“Š ~8000ãƒˆãƒ¼ã‚¯ãƒ³/å›")
        st.write("ğŸ’° é«˜ã‚³ã‚¹ãƒˆ")
    
    with col2:
        st.write("**CAPTãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**")
        st.write("âœ… åˆå›ã®ã¿ãƒ•ãƒ«è§£æ")
        st.write("ğŸ“Š ~800ãƒˆãƒ¼ã‚¯ãƒ³/å›ï¼ˆ2å›ç›®ä»¥é™ï¼‰")
        st.write("ğŸ’° 90%å‰Šæ¸›")
```

---

## ğŸ“š Next Steps

1. **Test with real audio**: Use actual pronunciation assessments
2. **Tune prompts**: Adjust `generate_ai_feedback_from_prompt()` for better Japanese feedback
3. **Add visualization**: Show error locations on waveform
4. **Track progress**: Store feedback history across sessions
5. **Gamification**: Add badges for improvements

---

## ğŸ› Troubleshooting

**Issue**: Feedback not displaying
- Check `st.session_state.ai_feedback_text` is not None
- Verify OpenAI client is initialized
- Check console for errors

**Issue**: Token usage still high
- Ensure using `attempt_summary` for subsequent attempts
- Verify `guidance_card` is saved and reused
- Check `is_first_attempt` flag is correct

**Issue**: Japanese feedback quality poor
- Adjust temperature (0.7 recommended)
- Use GPT-4 instead of GPT-3.5
- Refine system prompt

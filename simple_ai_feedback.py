"""
Simplified AI Feedback - No complex CAPT pipeline needed!
Just extract key info from Azure JSON and let AI do the heavy lifting.
"""
import streamlit as st


def extract_pronunciation_errors(azure_json):
    """
    Extract key pronunciation information from Azure Speech Assessment JSON.
    
    Args:
        azure_json: The pronunciation assessment result from Azure
        
    Returns:
        dict: Simplified error information
    """
    try:
        # Overall scores
        overall_score = azure_json.get("NBest", [{}])[0].get("PronunciationAssessment", {}).get("PronScore", 0)
        accuracy_score = azure_json.get("NBest", [{}])[0].get("PronunciationAssessment", {}).get("AccuracyScore", 0)
        fluency_score = azure_json.get("NBest", [{}])[0].get("PronunciationAssessment", {}).get("FluencyScore", 0)
        completeness_score = azure_json.get("NBest", [{}])[0].get("PronunciationAssessment", {}).get("CompletenessScore", 0)
        
        # Prosody
        prosody = azure_json.get("NBest", [{}])[0].get("PronunciationAssessment", {}).get("Prosody", {})
        
        # Extract problematic words (score < 70)
        words = azure_json.get("NBest", [{}])[0].get("Words", [])
        problem_words = []
        
        for word in words:
            word_text = word.get("Word", "")
            word_score = word.get("PronunciationAssessment", {}).get("AccuracyScore", 100)
            
            if word_score < 70:  # Threshold for "problematic"
                # Get phoneme errors
                phoneme_errors = []
                for phoneme in word.get("Phonemes", []):
                    phoneme_score = phoneme.get("PronunciationAssessment", {}).get("AccuracyScore", 100)
                    if phoneme_score < 70:
                        phoneme_errors.append({
                            "phoneme": phoneme.get("Phoneme", ""),
                            "score": phoneme_score
                        })
                
                problem_words.append({
                    "word": word_text,
                    "score": word_score,
                    "phoneme_errors": phoneme_errors
                })
        
        return {
            "overall_score": overall_score,
            "accuracy_score": accuracy_score,
            "fluency_score": fluency_score,
            "completeness_score": completeness_score,
            "prosody": prosody,
            "problem_words": problem_words
        }
    
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        return None


def generate_simple_ai_feedback(client, azure_json, reference_text, attempt_number=1, previous_errors=None):
    """
    Generate AI feedback directly from Azure JSON - no complex pipeline!
    
    Args:
        client: OpenAI client
        azure_json: Azure pronunciation assessment result
        reference_text: The text the user should pronounce
        attempt_number: Current attempt number
        previous_errors: Previous errors for comparison (optional)
        
    Returns:
        str: AI-generated feedback in Japanese
    """
    
    # Extract key information
    info = extract_pronunciation_errors(azure_json)
    if not info:
        return "è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"
    
    # Build prompt
    system_prompt = """ã‚ãªãŸã¯å­¦ç¿’è€…ã®å°‚å±ç™ºéŸ³ãƒãƒ¥ãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚æ¸©ã‹ãã€è¦ªã—ã¿ã‚„ã™ãã€åŠ±ã¾ã—ãªãŒã‚‰æŒ‡å°ã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®ç‚¹ã‚’å«ã‚ã¦ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã—ã¦ãã ã•ã„ï¼š
1. ğŸ¯ å‰å‘ãã§å…·ä½“çš„ãªè©•ä¾¡ã‹ã‚‰å§‹ã‚ã‚‹
2. ğŸ’¡ ãƒŸã‚¹ãŒã‚ã‚‹å ´åˆï¼šãªãœãã®ãƒŸã‚¹ãŒèµ·ããŸã®ã‹ã€ä¼šè©±èª¿ã§åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜
   ã€€ ãƒŸã‚¹ãŒãªã„å ´åˆï¼šä»Šå›ã®ç™ºéŸ³ã®è‰¯ã‹ã£ãŸç‚¹ã‚’å…·ä½“çš„ã«è¤’ã‚ã€éŸ»å¾‹é¢ã§ã®æ”¹å–„ç‚¹ãŒã‚ã‚Œã°å„ªã—ãæŒ‡æ‘˜
3. ğŸ—£ï¸ ã‚·ãƒ³ãƒ—ãƒ«ãªè¨€è‘‰ã§ã€å®Ÿä¾‹ã‚’ä½¿ã£ã¦èª¬æ˜
4. âœ¨ å…·ä½“çš„ã§å®Ÿè·µã—ã‚„ã™ã„ç·´ç¿’æ–¹æ³•ã‚’2ã€œ3å€‹ææ¡ˆ
5. ğŸŒŸ æ¬¡å›ã«å‘ã‘ãŸåŠ±ã¾ã—ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§çµ‚ã‚ã‚‹

é‡è¦ãªãƒ«ãƒ¼ãƒ«ï¼š
- ç™ºéŸ³èª¬æ˜ã¯å¿…ãšIPAï¼ˆå›½éš›éŸ³å£°è¨˜å·ï¼‰ã‚’ä½¿ç”¨
- ã‚«ã‚¿ã‚«ãƒŠã‚„ä»®åã¯ä½¿ã‚ãªã„
- ã¾ã‚‹ã§éš£ã«ã„ã‚‹ã‹ã®ã‚ˆã†ãªã€ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ã§è¦ªã—ã¿ã‚„ã™ã„å£èª¿
- æ—¥æœ¬èªã§å›ç­”"""
    
    # Build user prompt
    user_prompt = f"""ã€ç·´ç¿’ #{attempt_number} ã®ç™ºéŸ³è©•ä¾¡ã€‘

å‚ç…§ãƒ†ã‚­ã‚¹ãƒˆ: "{reference_text}"

**ã‚¹ã‚³ã‚¢:**
- ç·åˆ: {info['overall_score']:.0f}/100
- æ­£ç¢ºã•: {info['accuracy_score']:.0f}/100
- æµæš¢ã•: {info['fluency_score']:.0f}/100
- å®Œå…¨æ€§: {info['completeness_score']:.0f}/100

"""
    
    if info['problem_words']:
        # Has errors
        user_prompt += "**ç™ºéŸ³ãŒé›£ã—ã‹ã£ãŸå˜èª:**\n"
        for pw in info['problem_words'][:5]:  # Top 5
            user_prompt += f"- '{pw['word']}' (ã‚¹ã‚³ã‚¢: {pw['score']:.0f}/100)\n"
            if pw['phoneme_errors']:
                phonemes = ", ".join([p['phoneme'] for p in pw['phoneme_errors'][:3]])
                user_prompt += f"  å•é¡Œã®ã‚ã‚‹éŸ³ç´ : {phonemes}\n"
        
        user_prompt += "\nã“ã‚Œã‚‰ã®ãƒŸã‚¹ãŒãªãœèµ·ããŸã®ã‹ã€ã©ã†ç›´ã›ã°ã„ã„ã‹ã€å„ªã—ãæ•™ãˆã¦ãã ã•ã„ã€‚"
    else:
        # No errors - praise!
        user_prompt += "**ç´ æ™´ã‚‰ã—ã„ï¼ç™ºéŸ³ãƒŸã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚**\n\n"
        
        if previous_errors:
            user_prompt += f"å‰å›ã¯ {len(previous_errors)} å€‹ã®å˜èªã§è‹¦åŠ´ã—ã¦ã„ã¾ã—ãŸãŒã€ä»Šå›ã¯å®Œç’§ã§ã™ï¼\n\n"
        
        user_prompt += "ä»Šå›ã®ç™ºéŸ³ã®è‰¯ã‹ã£ãŸç‚¹ã‚’å…·ä½“çš„ã«è¤’ã‚ã¦ãã ã•ã„ã€‚\n"
        
        # Add prosody info if available
        if info['prosody']:
            user_prompt += f"éŸ»å¾‹è©•ä¾¡: {info['prosody']}\n"
        
        user_prompt += "å¯èƒ½ã§ã‚ã‚Œã°ã€éŸ»å¾‹ï¼ˆã‚¤ãƒ³ãƒˆãƒãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒªã‚ºãƒ ã€å¼·å‹¢ãªã©ï¼‰ã®é¢ã§ã•ã‚‰ã«è‰¯ãã§ãã‚‹ç‚¹ãŒã‚ã‚Œã°å„ªã—ãææ¡ˆã—ã¦ãã ã•ã„ã€‚"
    
    user_prompt += "\n\næ¸©ã‹ãåŠ±ã¾ã—ãªãŒã‚‰ã€æ¬¡ã®ç·´ç¿’ã¸ã®ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é«˜ã‚ã¦ãã ã•ã„ã€‚"
    
    # Get model name
    try:
        model_name = st.secrets["AzureGPT"].get("DEPLOYMENT_NAME", "gpt-5-mini")
    except:
        model_name = "gpt-5-mini"
    
    # Call AI
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ]
        )
        
        content = response.choices[0].message.content
        return content if content else "AIãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
    
    except Exception as e:
        st.error(f"AIç”Ÿæˆã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {str(e)}")
        
        # Fallback: Simple text feedback
        feedback = f"## ç·´ç¿’ #{attempt_number} ã®è©•ä¾¡\n\n"
        feedback += f"**ç·åˆã‚¹ã‚³ã‚¢:** {info['overall_score']:.0f}/100\n\n"
        
        if info['problem_words']:
            feedback += "**æ”¹å–„ãŒå¿…è¦ãªå˜èª:**\n"
            for pw in info['problem_words'][:5]:
                feedback += f"- {pw['word']} ({pw['score']:.0f}ç‚¹)\n"
        else:
            feedback += "**ç´ æ™´ã‚‰ã—ã„ï¼å…¨ã¦ã®å˜èªã‚’æ­£ç¢ºã«ç™ºéŸ³ã§ãã¾ã—ãŸï¼** ğŸ‰\n"
        
        return feedback


def generate_simple_ai_feedback_streaming(client, azure_json, reference_text, attempt_number=1, previous_errors=None):
    """
    Generate AI feedback with streaming - for better UX!
    
    Args:
        client: OpenAI client
        azure_json: Azure pronunciation assessment result
        reference_text: The text the user should pronounce
        attempt_number: Current attempt number
        previous_errors: Previous errors for comparison (optional)
        
    Yields:
        str: Chunks of AI-generated feedback
    """
    
    # Extract key information
    info = extract_pronunciation_errors(azure_json)
    if not info:
        yield "è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"
        return
    
    # Build prompt (same as non-streaming version)
    system_prompt = """ã‚ãªãŸã¯å­¦ç¿’è€…ã®å°‚å±ç™ºéŸ³ãƒãƒ¥ãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚æ¸©ã‹ãã€è¦ªã—ã¿ã‚„ã™ãã€åŠ±ã¾ã—ãªãŒã‚‰æŒ‡å°ã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®ç‚¹ã‚’å«ã‚ã¦ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã—ã¦ãã ã•ã„ï¼š
1. ğŸ¯ å‰å‘ãã§å…·ä½“çš„ãªè©•ä¾¡ã‹ã‚‰å§‹ã‚ã‚‹
2. ğŸ’¡ ãƒŸã‚¹ãŒã‚ã‚‹å ´åˆï¼šãªãœãã®ãƒŸã‚¹ãŒèµ·ããŸã®ã‹ã€ä¼šè©±èª¿ã§åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜
   ã€€ ãƒŸã‚¹ãŒãªã„å ´åˆï¼šä»Šå›ã®ç™ºéŸ³ã®è‰¯ã‹ã£ãŸç‚¹ã‚’å…·ä½“çš„ã«è¤’ã‚ã€éŸ»å¾‹é¢ã§ã®æ”¹å–„ç‚¹ãŒã‚ã‚Œã°å„ªã—ãæŒ‡æ‘˜
3. ğŸ—£ï¸ ã‚·ãƒ³ãƒ—ãƒ«ãªè¨€è‘‰ã§ã€å®Ÿä¾‹ã‚’ä½¿ã£ã¦èª¬æ˜
4. âœ¨ å…·ä½“çš„ã§å®Ÿè·µã—ã‚„ã™ã„ç·´ç¿’æ–¹æ³•ã‚’2ã€œ3å€‹ææ¡ˆ
5. ğŸŒŸ æ¬¡å›ã«å‘ã‘ãŸåŠ±ã¾ã—ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§çµ‚ã‚ã‚‹

é‡è¦ãªãƒ«ãƒ¼ãƒ«ï¼š
- ç™ºéŸ³èª¬æ˜ã¯å¿…ãšIPAï¼ˆå›½éš›éŸ³å£°è¨˜å·ï¼‰ã‚’ä½¿ç”¨
- ã‚«ã‚¿ã‚«ãƒŠã‚„ä»®åã¯ä½¿ã‚ãªã„
- ã¾ã‚‹ã§éš£ã«ã„ã‚‹ã‹ã®ã‚ˆã†ãªã€ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ã§è¦ªã—ã¿ã‚„ã™ã„å£èª¿
- æ—¥æœ¬èªã§å›ç­”"""
    
    # Build user prompt based on whether there are errors or not
    has_errors = info['problem_words'] and len(info['problem_words']) > 0
    
    user_prompt = f"""ã€ç·´ç¿’ #{attempt_number} ã®ç™ºéŸ³è©•ä¾¡ã€‘

å‚ç…§ãƒ†ã‚­ã‚¹ãƒˆ: "{reference_text}"

**ã‚¹ã‚³ã‚¢:**
- ç·åˆ: {info['overall_score']:.0f}/100
- æ­£ç¢ºã•: {info['accuracy_score']:.0f}/100
- æµæš¢ã•: {info['fluency_score']:.0f}/100
- å®Œå…¨æ€§: {info['completeness_score']:.0f}/100

"""
    
    if has_errors:
        # Has errors
        user_prompt += "**ç™ºéŸ³ãŒé›£ã—ã‹ã£ãŸå˜èª:**\n"
        for pw in info['problem_words'][:5]:
            user_prompt += f"- '{pw['word']}' (ã‚¹ã‚³ã‚¢: {pw['score']:.0f}/100)\n"
            if pw['phoneme_errors']:
                phonemes = ", ".join([p['phoneme'] for p in pw['phoneme_errors'][:3]])
                user_prompt += f"  å•é¡Œã®ã‚ã‚‹éŸ³ç´ : {phonemes}\n"
        
        user_prompt += "\nã“ã‚Œã‚‰ã®ãƒŸã‚¹ãŒãªãœèµ·ããŸã®ã‹ã€ã©ã†ç›´ã›ã°ã„ã„ã‹ã€å„ªã—ãæ•™ãˆã¦ãã ã•ã„ã€‚"
    else:
        # No errors - praise!
        user_prompt += "**ç´ æ™´ã‚‰ã—ã„ï¼ç™ºéŸ³ãƒŸã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚**\n\n"
        
        if previous_errors:
            user_prompt += f"å‰å›ã¯ {len(previous_errors)} å€‹ã®å˜èªã§è‹¦åŠ´ã—ã¦ã„ã¾ã—ãŸãŒã€ä»Šå›ã¯å®Œç’§ã§ã™ï¼\n\n"
        
        user_prompt += "ä»Šå›ã®ç™ºéŸ³ã®è‰¯ã‹ã£ãŸç‚¹ã‚’å…·ä½“çš„ã«è¤’ã‚ã¦ãã ã•ã„ã€‚\n"
        
        if info['prosody']:
            user_prompt += f"éŸ»å¾‹è©•ä¾¡: {info['prosody']}\n"
        
        user_prompt += "å¯èƒ½ã§ã‚ã‚Œã°ã€éŸ»å¾‹ï¼ˆã‚¤ãƒ³ãƒˆãƒãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒªã‚ºãƒ ã€å¼·å‹¢ãªã©ï¼‰ã®é¢ã§ã•ã‚‰ã«è‰¯ãã§ãã‚‹ç‚¹ãŒã‚ã‚Œã°å„ªã—ãææ¡ˆã—ã¦ãã ã•ã„ã€‚"
    
    user_prompt += "\n\næ¸©ã‹ãåŠ±ã¾ã—ãªãŒã‚‰ã€æ¬¡ã®ç·´ç¿’ã¸ã®ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é«˜ã‚ã¦ãã ã•ã„ã€‚"
    
    # Get model name
    try:
        model_name = st.secrets["AzureGPT"].get("DEPLOYMENT_NAME", "gpt-5-mini")
    except:
        model_name = "gpt-5-mini"
    
    # Call AI with streaming
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            stream=True  # Enable streaming!
        )
        
        # Yield chunks as they arrive
        for chunk in response:
            # Check if chunk has choices and content
            if chunk.choices and len(chunk.choices) > 0:
                delta = chunk.choices[0].delta
                if hasattr(delta, 'content') and delta.content:
                    yield delta.content
    
    except Exception as e:
        # Fallback on error
        yield f"\n\nâš ï¸ AIç”Ÿæˆã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {str(e)}\n\n"
        yield f"## ç·´ç¿’ #{attempt_number} ã®è©•ä¾¡\n\n"
        yield f"**ç·åˆã‚¹ã‚³ã‚¢:** {info['overall_score']:.0f}/100\n\n"
        
        if info['problem_words']:
            yield "**æ”¹å–„ãŒå¿…è¦ãªå˜èª:**\n"
            for pw in info['problem_words'][:5]:
                yield f"- {pw['word']} ({pw['score']:.0f}ç‚¹)\n"
        else:
            yield "**ç´ æ™´ã‚‰ã—ã„ï¼å…¨ã¦ã®å˜èªã‚’æ­£ç¢ºã«ç™ºéŸ³ã§ãã¾ã—ãŸï¼** ğŸ‰\n"
